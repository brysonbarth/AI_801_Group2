{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is where we will test our code. We may convert all code to a .py file if necessary\n",
    "# global variables\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 4\n",
    "WIN_STATE = (0, 3)\n",
    "LOSE_STATE = (1, 3)\n",
    "START = (2, 0)\n",
    "DETERMINISTIC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveReward(self):\n",
    "        if self.state == WIN_STATE:\n",
    "            return 1\n",
    "        elif self.state == LOSE_STATE:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nxtPosition(self, action):\n",
    "        \"\"\"\n",
    "        action: up, down, left, right\n",
    "        -------------\n",
    "        0 | 1 | 2| 3|\n",
    "        1 |\n",
    "        2 |\n",
    "        return next position\n",
    "        \"\"\"\n",
    "        if self.determine:\n",
    "            if action == \"up\":\n",
    "                nxtState = (self.state[0] - 1, self.state[1])\n",
    "            elif action == \"down\":\n",
    "                nxtState = (self.state[0] + 1, self.state[1])\n",
    "            elif action == \"left\":\n",
    "                nxtState = (self.state[0], self.state[1] - 1)\n",
    "            else:\n",
    "                nxtState = (self.state[0], self.state[1] + 1)\n",
    "            # if next state legal\n",
    "            if (nxtState[0] >= 0) and (nxtState[0] <= 2):\n",
    "                if (nxtState[1] >= 0) and (nxtState[1] <= 3):\n",
    "                    if nxtState != (1, 1):\n",
    "                        return nxtState\n",
    "            return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(self, rounds=10):\n",
    "        i = 0\n",
    "        while i < rounds:\n",
    "            # to the end of game back propagate reward\n",
    "            if self.State.isEnd:\n",
    "                # back propagate\n",
    "                reward = self.State.giveReward()\n",
    "                # explicitly assign end state to reward values\n",
    "                self.state_values[self.State.state] = reward  # this is optional\n",
    "                print(\"Game End Reward\", reward)\n",
    "                for s in reversed(self.states):\n",
    "                    reward = self.state_values[s] + self.lr * (reward - self.state_values[s])\n",
    "                    self.state_values[s] = round(reward, 3)\n",
    "                self.reset()\n",
    "                i += 1\n",
    "            else:\n",
    "                action = self.chooseAction()\n",
    "                # append trace\n",
    "                self.states.append(self.State.nxtPosition(action))\n",
    "                print(\"current position {} action {}\".format(self.State.state, action))\n",
    "                # by taking the action, it reaches the next state\n",
    "                self.State = self.takeAction(action)\n",
    "                # mark is end\n",
    "                self.State.isEndFunc()\n",
    "                print(\"nxt state\", self.State.state)\n",
    "                print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseAction(self):\n",
    "        # choose action with most expected value\n",
    "        mx_nxt_reward = 0\n",
    "        action = \"\"\n",
    "\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # greedy action\n",
    "            for a in self.actions:\n",
    "                # if the action is deterministic\n",
    "                nxt_reward = self.state_values[self.State.nxtPosition(a)]\n",
    "                if nxt_reward >= mx_nxt_reward:\n",
    "                    action = a\n",
    "                    mx_nxt_reward = nxt_reward\n",
    "        return action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd0a3b1226fed31d723cadfa132eee30e723a9c5914e8e647192f2f947eeb4c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
